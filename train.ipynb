{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1996eff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import chess_utils\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f90277",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba55085",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "data += chess_utils.extract_training_data(\"games/jalba20-black.pgn\", my_color=\"black\")\n",
    "data += chess_utils.extract_training_data(\"games/Jeedy20-black.pgn\", my_color=\"black\")\n",
    "data += chess_utils.extract_training_data(\"games/jalba20-white.pgn\", my_color=\"white\")\n",
    "data += chess_utils.extract_training_data(\"games/Jeedy20-white.pgn\", my_color=\"white\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b614b6",
   "metadata": {},
   "source": [
    "## Create tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba611f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list of tuples to separate arrays\n",
    "X = np.array([item[0] for item in data], dtype=np.float32)  # Extract tensors\n",
    "y = np.array([item[1] for item in data], dtype=np.long)     # Extract policy indices\n",
    "\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318d19e1",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2873f10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import ChessDataset\n",
    "from model import ChessModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "486e35ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "dataset = ChessDataset(X, y)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# check for cuda on device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "model = ChessModel(input_channels=19).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c274208c",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d74ffa",
   "metadata": {},
   "source": [
    "### Model Architecture Hyperparameters:\n",
    "\n",
    "input_channels: 19\\\n",
    "conv_filters: [64, 128, 256]\\\n",
    "kernel_size: 3\\\n",
    "padding: 1\\\n",
    "hidden_size: 1024\\\n",
    "output_size: 4288\\\n",
    "dropout_rate: 0.3\n",
    "\n",
    "### Training Hyperparameters:\n",
    "\n",
    "batch_size: 64\\\n",
    "learning_rate: 0.0001\\\n",
    "num_epochs: 250\\\n",
    "optimizer: Adam\\\n",
    "loss_function: CrossEntropyLoss\\\n",
    "gradient_clipping: max_norm=1.0\\\n",
    "shuffle: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884bbca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 0/3344 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 3344/3344 [07:29<00:00,  7.44it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Loss: 5.9110, Time: 7m 29s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 250\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in tqdm.tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        policy_logits = model(inputs)\n",
    "        loss = criterion(policy_logits, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time\n",
    "    minutes = int(epoch_time // 60)\n",
    "    seconds = int(epoch_time) - minutes * 60\n",
    "    \n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Time: {minutes}m {seconds}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1900f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_path = \"models/TORCH_250EPOCH.pth\"\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'epoch': num_epochs,\n",
    "    'loss': avg_loss,\n",
    "}, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df6d192",
   "metadata": {},
   "source": [
    "## Convert to format compatible with C++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5888e632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An instance of your model.\n",
    "model, device = chess_utils.load_model(\"models/TORCH_250EPOCH.pth\")\n",
    "\n",
    "# An example input you would normally provide to your model's forward() method.\n",
    "board = chess.Board()\n",
    "X = chess_utils.board_to_tensor(board)\n",
    "example = torch.tensor(X, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "# Use torch.jit.trace to generate a torch.jit.ScriptModule via tracing.\n",
    "traced_script_module = torch.jit.trace(model, example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fafbf1",
   "metadata": {},
   "source": [
    "### Check that the model is compatible with TorchScript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d762e9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is TorchScript compatible via scripting\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Try scripting first (more comprehensive than tracing)\n",
    "    scripted_module = torch.jit.script(model)\n",
    "    print(\"Model is TorchScript compatible via scripting\")\n",
    "    scripted_module.save(\"models/scripted_1EPOCH_model.pt\")\n",
    "except Exception as e:\n",
    "    print(f\"Scripting failed: {e}\")\n",
    "    print(\"Falling back to tracing...\")\n",
    "    \n",
    "    # If scripting fails, use tracing with warnings\n",
    "    with torch.jit.optimized_execution(False):\n",
    "        traced_script_module = torch.jit.trace(model, example, strict=False)\n",
    "    traced_script_module.save(\"models/traced_1EPOCH_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca7e5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_script_module.save(\"models/traced_250EPOCH_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f6f449",
   "metadata": {},
   "source": [
    "### Test loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada192a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loads and runs successfully in Python\n",
      "Output shape: torch.Size([1, 4288])\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    loaded_model = torch.jit.load(\"models/traced_250EPOCH_model.pt\")\n",
    "    loaded_model.eval()\n",
    "    \n",
    "    # Test with the same input\n",
    "    with torch.no_grad():\n",
    "        output = loaded_model(example)\n",
    "    print(\"Model loads and runs successfully in Python\")\n",
    "    print(f\"Output shape: {output.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading traced model in Python: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a99566",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chess-ai-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
